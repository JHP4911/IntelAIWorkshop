{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to actually build a neural network from blocks?\n",
    "\n",
    "## Installation\n",
    "\n",
    "* Python 3 with Jupyter Notebook, Tensorflow and Keras\n",
    "\n",
    "* [keras-sequential-ascii](https://github.com/stared/keras-sequential-ascii) for diagrams\n",
    "```bash\n",
    "$ pip install git+git://github.com/stared/keras-sequential-ascii.git\n",
    "$ wget http://yaroslavvb.com/upload/notMNIST/notMNIST_small.mat\n",
    "```\n",
    "\n",
    "## Data\n",
    "\n",
    "Data source: [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) (you need to download `notMNIST_small.mat` file):\n",
    "\n",
    "> some publicly available fonts and extracted glyphs from them to make a dataset similar to MNIST. There are 10 classes, with letters A-J taken from different fonts.\n",
    "\n",
    "> Approaching 0.5% error rate on notMNIST_small would be very impressive. If you run your algorithm on this dataset, please let me know your results.\n",
    "\n",
    "## More info\n",
    "\n",
    "For additional information, including [some context for notMNIST](http://p.migdal.pl/2017/04/30/teaching-deep-learning.html#notmnist), see [Learning Deep Learning with Keras](http://p.migdal.pl/2017/04/30/teaching-deep-learning.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "from live_loss_plot import PlotLosses\n",
    "\n",
    "# Keras layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, BatchNormalization, GlobalMaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = io.loadmat(\"datasets/notMNIST_small.mat\")\n",
    "\n",
    "# transform data\n",
    "X = data['images']\n",
    "y = data['labels']\n",
    "resolution = 28\n",
    "classes = 10\n",
    "\n",
    "X = np.transpose(X, (2, 0, 1))\n",
    "\n",
    "y = y.astype('int32')\n",
    "X = X.astype('float32') / 255.\n",
    "\n",
    "# channel for X\n",
    "X = X.reshape((-1, resolution, resolution, 1))\n",
    "\n",
    "# 3 -> [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]\n",
    "Y = np_utils.to_categorical(y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random letters\n",
    "rows = 6\n",
    "fig, axs = plt.subplots(rows, classes, figsize=(classes, rows))\n",
    "for letter_id in range(10):\n",
    "    letters = X[y == letter_id]\n",
    "    for i in range(rows):\n",
    "        ax = axs[i, letter_id]\n",
    "        ax.imshow(letters[np.random.randint(len(letters)),:,:,0],\n",
    "                  cmap='Greys', interpolation='none')\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_losses = PlotLosses(figsize=(8, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_models, training_times = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(resolution, resolution, 1)))\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "sequential_model_to_ascii_printout(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "# train model\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test), callbacks=[plot_losses])\n",
    "end_time = time()\n",
    "trained_models.append(model)\n",
    "training_times.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(resolution, resolution, 1)))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "sequential_model_to_ascii_printout(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "# train model\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test), callbacks=[plot_losses])\n",
    "end_time = time()\n",
    "trained_models.append(model)\n",
    "training_times.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 conv\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu',\n",
    "                 input_shape=(resolution, resolution, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "sequential_model_to_ascii_printout(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "# train model\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test), callbacks=[plot_losses])\n",
    "end_time = time()\n",
    "trained_models.append(model)\n",
    "training_times.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 conv + max pool\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu',\n",
    "                 input_shape=(resolution, resolution, 1)))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "sequential_model_to_ascii_printout(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "# train model\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test), callbacks=[plot_losses])\n",
    "end_time = time()\n",
    "trained_models.append(model)\n",
    "training_times.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x (conv + max pool)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu',\n",
    "                 input_shape=(resolution, resolution, 1)))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "sequential_model_to_ascii_printout(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "# train model\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test), callbacks=[plot_losses])\n",
    "end_time = time()\n",
    "trained_models.append(model)\n",
    "training_times.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x (conv + max pool) more channels\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',\n",
    "                 input_shape=(resolution, resolution, 1)))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "sequential_model_to_ascii_printout(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "# train model\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test), callbacks=[plot_losses])\n",
    "end_time = time()\n",
    "trained_models.append(model)\n",
    "training_times.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x (2xconv + max pool)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu',\n",
    "                 input_shape=(resolution, resolution, 1)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "sequential_model_to_ascii_printout(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "# train model\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test), callbacks=[plot_losses])\n",
    "end_time = time()\n",
    "trained_models.append(model)\n",
    "training_times.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x (2xconv + max pool) dropout bn\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu',\n",
    "                 input_shape=(resolution, resolution, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "sequential_model_to_ascii_printout(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "# train model\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test), callbacks=[plot_losses])\n",
    "end_time = time()\n",
    "trained_models.append(model)\n",
    "training_times.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x (2xconv + max pool) dropout bn\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu',\n",
    "                 input_shape=(resolution, resolution, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "sequential_model_to_ascii_printout(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "# train model\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test), callbacks=[plot_losses])\n",
    "end_time = time()\n",
    "trained_models.append(model)\n",
    "training_times.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x (2xconv + max pool + dense) dropout bn\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu',\n",
    "                 input_shape=(resolution, resolution, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "sequential_model_to_ascii_printout(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "# train model\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test), callbacks=[plot_losses])\n",
    "end_time = time()\n",
    "trained_models.append(model)\n",
    "training_times.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully conv\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu',\n",
    "                 input_shape=(resolution, resolution, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(GlobalMaxPool2D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "sequential_model_to_ascii_printout(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "# train model\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test), callbacks=[plot_losses])\n",
    "end_time = time()\n",
    "trained_models.append(model)\n",
    "training_times.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "rows = 16\n",
    "fig, axs = plt.subplots(rows, 2, figsize=(8, 1.5 * rows))\n",
    "for i in range(rows):\n",
    "    ax = axs[i,0]\n",
    "    idx = np.random.randint(len(X_test))\n",
    "    ax.imshow(X_test[idx,:,:,0],\n",
    "              cmap='Greys', interpolation='none')\n",
    "    ax.axis('off')\n",
    "        \n",
    "    pd.Series(predictions[idx], index=list(\"ABCDEFGHIJ\")).plot('bar', ax=axs[i,1], ylim=[0,1])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Grid Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from grid_plot import score_model_grid, plot_complexity, plot_loss_grid, plot_acc_grid\n",
    "\n",
    "model_names = ['logistic regression', \n",
    "'multi layer perceptron', \n",
    "'1 conv layer 16 filters 3x3',\n",
    "'1 conv layer 16 filters 3x3 with maxpool',\n",
    "'2 conv layer 16 and 32 filters 3x3 with maxpool',\n",
    "'2 conv layer 64 filters 3x3 with maxpool',\n",
    "'2 blocks of 2 conv layer 16 and 32 filters 3x3 with maxpool',\n",
    "'2 blocks of 2 conv layer 16 and 32 filters 3x3 with maxpool and dropout',\n",
    "'2 blocks of 2 conv layer 16 and 32 filters 3x3 with maxpool with dropout with batch normalization',      \n",
    "'2 blocks of 2 conv layer 16 and 32 filters 3x3 with maxpool, dense layer with dropout with batch normalization',\n",
    "'2 blocks of 2 conv layer 16 and 32 filters 3x3 with maxpool, global average pooling layer with dropout with batch normalization'\n",
    "]\n",
    "\n",
    "model_grid = score_model_grid(trained_models, model_names, training_times, \n",
    "                              X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "model_grid.to_csv('model_grid_scores.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_complexity(save_path='model_grid_scores.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_grid(save_path='model_grid_scores.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_grid(save_path='model_grid_scores.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
